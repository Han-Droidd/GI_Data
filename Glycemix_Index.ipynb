{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required Packages\n",
    "import requests\n",
    "import os \n",
    "from PIL import Image\n",
    "from IPython.display import IFrame\n",
    "!pip3 install requests beautifulsoup4 --user\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Glycemix index stated and less than is listed\n",
    "gi_index = \"120\"\n",
    "\n",
    "# Initial DataFrame Columns\n",
    "food_data = pd.DataFrame(  columns = list([ \"Name\", \"GI\", \"Serve (g)\", \"Carb Per Serve\", \"GL\" ]) )\n",
    "\n",
    "# Finds max number of pages\n",
    "page_first = \"1\"\n",
    "url = \"http://www.glycemicindex.com/foodSearch.php?ak=list&food_name_search_type=cn&food_name=&\\\n",
    "gi_search_type=lte&gi={}\\\n",
    "&gl_search_type=lte&gl=&country=&product_category=&\\\n",
    "lop=AND&orderBy=GIG&find=Find+Records&page={}\".format(gi_index,page_first)\n",
    "html_content =requests.get(url).text\n",
    "soup = BeautifulSoup(html_content, \"lxml\")\n",
    "table = soup.find( 'table' )\n",
    "table = table.find_all('p')\n",
    "html_row = str(table).split('&amp;ak=detail\">')[0]\n",
    "max_page_num = int( re.search( \"page {} of .*  -\".format(page_first), html_row ).group(0).split(\"of\")[1][1:-3] )\n",
    "\n",
    "for page_num in range ( 1, max_page_num +1 ):\n",
    "    \n",
    "    # Formats url for page number\n",
    "    url = \"http://www.glycemicindex.com/foodSearch.php?ak=list&food_name_search_type=cn&food_name=&\\\n",
    "    gi_search_type=lte&gi={}\\\n",
    "    &gl_search_type=lte&gl=&country=&product_category=&\\\n",
    "    lop=AND&orderBy=GIG&find=Find+Records&page={}\".format(gi_index,page_num)\n",
    "    \n",
    "    # Extracts table html\n",
    "    html_content =requests.get(url).text\n",
    "    soup = BeautifulSoup(html_content, \"lxml\")\n",
    "    table = soup.find( 'table' )\n",
    "    table = table.find_all('p')\n",
    "    \n",
    "    # Extracts nutrition data per page\n",
    "    if re.search( \"Results page '{}' not found\".format(str(page_num)), str(table) ) != None:\n",
    "        page_num = -1\n",
    "        print(\"Extraction complete.\")\n",
    "    else:           \n",
    "        for i in range ( 1, len(str(table).split('&amp;ak=detail\">')) ):\n",
    "            html_row = str(table).split('&amp;ak=detail\">')[i]\n",
    "            # print( str(table).split('&amp;ak=detail\">')[i] + \"\\n\" )\n",
    "            food_name = html_row.split(\"</a>\")[0]\n",
    "            food_values = []  \n",
    "            for ii in range( 1, 5 ):\n",
    "                # food_values_name = [ \"GI\", \"Serve (g)\", \"Carb Per Serve\", \"GL\" ]\n",
    "                food_values.append(html_row.split(\"</p>\")[ii].split('<p class=\"body\">')[ \\\n",
    "                len(html_row.split(\"</p>\")[ii].split('<p class=\"body\">')) -1 ] )\n",
    "                page_num = page_num + 1\n",
    "                \n",
    "            food_data.loc[ len(food_data) ]  = ( list([food_name]) + food_values )\n",
    "                \n",
    "        if page_num == max_page_num:\n",
    "            print(\"Extraction complete.\")\n",
    "\n",
    "\n",
    "# print( food_data )\n",
    "food_data.to_excel( os.path.expanduser(\"~/Desktop/GI_data.xlsx\") )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
